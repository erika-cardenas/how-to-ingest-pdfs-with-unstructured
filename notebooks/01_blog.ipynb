{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn how to ingest a pdf file into weaviate using unstrcutured!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./pdf01_snippet.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert a pdf to text in just one function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = partition_pdf(filename=\"../data/paper01.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A survey on Image Data Augmentation for Deep Learning\n",
      "Connor Shorten* and Taghi M. Khoshgoftaar\n",
      "*Correspondence: cshorten2015@fau.edu Department of Computer and Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, USA\n",
      "Abstract\n",
      "Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfor\n",
      "tunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data\n",
      "space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta\n",
      "learning. The applica\n",
      "tion of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other character\n",
      "istics of Data Augmentation such as test\n"
     ]
    }
   ],
   "source": [
    "for elem in elements[:10]:\n",
    "    print(elem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titles have their own category.\n",
    "\n",
    "Here's all the titles that unstructured was able to find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A survey on Image Data Augmentation for Deep Learning\n",
      "Abstract\n",
      "Introduction\n",
      "Background\n",
      "Image Data Augmentation techniques\n",
      "Data Augmentations based on basic image manipulations\n",
      "Flipping\n",
      "Color space\n",
      "Cropping\n",
      "Rotation\n",
      "Translation\n",
      "Noise injection\n",
      "Color space transformations\n",
      "Geometric versus photometric transformations\n",
      "Kernel filters\n",
      "Mixing images\n",
      "Random erasing\n",
      "A note on combining augmentations\n",
      "Data Augmentations based on Deep Feature space augmentation\n",
      "Data Augmentations based on Deep Learning\n",
      "Feature space augmentation\n",
      "Adversarial training\n",
      "GAN‑based Data Augmentation\n",
      "Generated images\n",
      "Neural Style Transfer\n",
      "Meta learning Data Augmentations\n",
      "Comparing Augmentations\n",
      "Design considerations for image Data Augmentation\n",
      "Test-time augmentation\n",
      "Curriculum learning\n",
      "Resolution impact\n",
      "Final dataset size\n",
      "Alleviating class imbalance with Data Augmentation\n",
      "Discussion\n",
      "Future work\n",
      "Conclusion\n",
      "Abbreviations\n",
      "Acknowledgements\n",
      "Authors’ contributions\n",
      "Funding\n",
      "References\n",
      "Publisher’s Note\n"
     ]
    }
   ],
   "source": [
    "titles = [elem for elem in elements if elem.category == \"Title\"]\n",
    "\n",
    "for title in titles:\n",
    "    print(title.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was able to recognize most of the titles, but not all of them. \n",
    "\n",
    "Example of missing titles:\n",
    "\n",
    "* Availability of data and materials\n",
    "* Competing interests\n",
    "* Consent for publication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of a title is a NarrativeText object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrative text 1:\n",
      "Connor Shorten* and Taghi M. Khoshgoftaar\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Narrative text 2:\n",
      "*Correspondence: cshorten2015@fau.edu Department of Computer and\n",
      "Electrical Engineering and Computer Science, Florida Atlantic\n",
      "University, Boca Raton, USA\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Narrative text 3:\n",
      "Deep convolutional neural networks have performed remarkably well on\n",
      "many Computer Vision tasks. However, these networks are heavily\n",
      "reliant on big data to avoid overfitting. Overfitting refers to the\n",
      "phenomenon when a network learns a function with very high variance\n",
      "such as to perfectly model the training data. Unfor- tunately, many\n",
      "application domains do not have access to big data, such as medical\n",
      "image analysis. This survey focuses on Data Augmentation, a data-space\n",
      "solution to the problem of limited data. Data Augmentation encompasses\n",
      "a suite of techniques that enhance the size and quality of training\n",
      "datasets such that better Deep Learning models can be built using\n",
      "them. The image augmentation algorithms discussed in survey include\n",
      "geometric transformations, color space augmentations, kernel filters,\n",
      "mixing images, random erasing, feature space augmentation, adversarial\n",
      "training, generative adversarial networks, neural style transfer, and\n",
      "meta-learning. The applica- tion of augmentation methods based on GANs\n",
      "are heavily covered in this survey. In addition to augmentation\n",
      "techniques, this paper will briefly discuss other character- istics of\n",
      "Data Augmentation such as test-time augmentation, resolution impact,\n",
      "final dataset size, and curriculum learning. This survey will present\n",
      "existing methods for Augmentation, promising developments, and meta-\n",
      "level decisions for implementing Data Augmentation. Readers will\n",
      "understand how Data Augmentation can improve the performance of their\n",
      "models and expand limited datasets to take advantage of capabilities\n",
      "of big data.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Narrative text 4:\n",
      "Data Augmentation, Big data, Image data, Deep Learning,\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Narrative text 5:\n",
      "Deep Learning models have made incredible progress in discriminative\n",
      "tasks. This has been fueled by the advancement of deep network\n",
      "architectures, powerful computation, and access to big data. Deep\n",
      "neural networks have been successfully applied to Com- puter Vision\n",
      "tasks such as image classification, object detection, and image\n",
      "segmenta- tion thanks to the development of convolutional neural\n",
      "networks (CNNs). These neural networks utilize parameterized, sparsely\n",
      "connected kernels which preserve the spatial characteristics of\n",
      "images. Convolutional layers sequentially downsample the spatial\n",
      "resolution of images while expanding the depth of their feature maps.\n",
      "This series of convolutional transformations can create much lower-\n",
      "dimensional and more useful rep- resentations of images than what\n",
      "could possibly be hand-crafted. The success of CNNs has spiked\n",
      "interest and optimism in applying Deep Learning to Computer Vision\n",
      "tasks.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "narrative_texts = [elem for elem in elements if elem.category == \"NarrativeText\"]\n",
    "\n",
    "for index, elem in enumerate(narrative_texts[:5]):\n",
    "    print(f\"Narrative text {index + 1}:\")\n",
    "    print(\"\\n\".join(textwrap.wrap(elem.text, width=70)))\n",
    "    print(\"\\n\" + \"-\" * 70 + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we could vectorize all the narrative texts and store it in weaviate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Stuff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we are only interested in extracted the abstract?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a state machine that can extract the narrative texts under the abstract section given a list of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "class AbstractExtractor:\n",
    "    def __init__(self):\n",
    "        self.current_section = None  # Keep track of the current section being processed\n",
    "        self.have_extracted_abstract = (\n",
    "            False  # Keep track of whether the abstract has been extracted\n",
    "        )\n",
    "        self.in_abstract_section = (\n",
    "            False  # Keep track of whether we're inside the Abstract section\n",
    "        )\n",
    "        self.texts = []  # Keep track of the extracted abstract text\n",
    "\n",
    "    def process(self, element):\n",
    "        if element.category == \"Title\":\n",
    "            self.set_section(element.text)\n",
    "\n",
    "            if self.current_section == \"Abstract\":\n",
    "                self.in_abstract_section = True\n",
    "                return True\n",
    "\n",
    "            if self.in_abstract_section:\n",
    "                return False\n",
    "\n",
    "        if self.in_abstract_section and element.category == \"NarrativeText\":\n",
    "            self.consume_abstract_text(element.text)\n",
    "            return True\n",
    "\n",
    "        return True\n",
    "\n",
    "    def set_section(self, text):\n",
    "        self.current_section = text\n",
    "        logging.info(f\"Current section: {self.current_section}\")\n",
    "\n",
    "    def consume_abstract_text(self, text):\n",
    "        logging.info(f\"Abstract part extracted: {text}\")\n",
    "        self.texts.append(text)\n",
    "\n",
    "    def consume_elements(self, elements):\n",
    "        for element in elements:\n",
    "            should_continue = self.process(element)\n",
    "\n",
    "            if not should_continue:\n",
    "                self.have_extracted_abstract = True\n",
    "                break\n",
    "\n",
    "        if not self.have_extracted_abstract:\n",
    "            logging.warning(\"No abstract found in the given list of objects.\")\n",
    "\n",
    "    def abstract(self):\n",
    "        return \"\\n\".join(self.texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Current section: A survey on Image Data Augmentation for Deep Learning\n",
      "INFO:root:Current section: Abstract\n",
      "INFO:root:Abstract part extracted: Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfor- tunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The applica- tion of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other character- istics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of capabilities of big data.\n",
      "INFO:root:Abstract part extracted: Data Augmentation, Big data, Image data, Deep Learning,\n",
      "INFO:root:Current section: Introduction\n"
     ]
    }
   ],
   "source": [
    "abstract_extractor = AbstractExtractor()\n",
    "abstract_extractor.consume_elements(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted abstract is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep convolutional neural networks have performed remarkably well on\n",
      "many Computer Vision tasks. However, these networks are heavily\n",
      "reliant on big data to avoid overfitting. Overfitting refers to the\n",
      "phenomenon when a network learns a function with very high variance\n",
      "such as to perfectly model the training data. Unfor- tunately, many\n",
      "application domains do not have access to big data, such as medical\n",
      "image analysis. This survey focuses on Data Augmentation, a data-space\n",
      "solution to the problem of limited data. Data Augmentation encompasses\n",
      "a suite of techniques that enhance the size and quality of training\n",
      "datasets such that better Deep Learning models can be built using\n",
      "them. The image augmentation algorithms discussed in survey include\n",
      "geometric transformations, color space augmentations, kernel filters,\n",
      "mixing images, random erasing, feature space augmentation, adversarial\n",
      "training, generative adversarial networks, neural style transfer, and\n",
      "meta-learning. The applica- tion of augmentation methods based on GANs\n",
      "are heavily covered in this survey. In addition to augmentation\n",
      "techniques, this paper will briefly discuss other character- istics of\n",
      "Data Augmentation such as test-time augmentation, resolution impact,\n",
      "final dataset size, and curriculum learning. This survey will present\n",
      "existing methods for Augmentation, promising developments, and meta-\n",
      "level decisions for implementing Data Augmentation. Readers will\n",
      "understand how Data Augmentation can improve the performance of their\n",
      "models and expand limited datasets to take advantage of capabilities\n",
      "of big data. Data Augmentation, Big data, Image data, Deep Learning,\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(textwrap.wrap(abstract_extractor.abstract(), width=70)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read a folder containing pdfs of papers, extract their abstracts and store them in weaviate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize weaviate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /home/.cache/weaviate-embedded: process ID 10617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2023-05-05T12:01:18Z\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2023-05-05T12:01:18Z\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2023-05-05T12:01:18Z\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":50000,\"index_id\":\"document_H3hGhHFqxwSF\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-05-05T12:01:18Z\",\"took\":1762513}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:6666\",\"time\":\"2023-05-05T12:01:18Z\"}\n",
      "/usr/local/lib/python3.8/subprocess.py:946: ResourceWarning: subprocess 10617 is still running\n",
      "  _warn(\"subprocess %s is still running\" % self.pid,\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(\n",
    "        additional_env_vars={\"OPENAI_APIKEY\": os.environ[\"OPENAI_APIKEY\"]}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":25000,\"index_id\":\"document_E98XgwOuptlB\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-05-05T12:01:18Z\",\"took\":1316246}\n"
     ]
    }
   ],
   "source": [
    "client.schema.delete_all()\n",
    "\n",
    "schema = {\n",
    "    \"class\": \"Document\",\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"source\",\n",
    "            \"dataType\": [\"text\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"abstract\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"moduleConfig\": {\n",
    "                \"text2vec-openai\": {\"skip\": False, \"vectorizePropertyName\": False}\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"moduleConfig\": {\n",
    "        \"generative-openai\": {},\n",
    "        \"text2vec-openai\": {\"model\": \"ada\", \"modelVersion\": \"002\", \"type\": \"text\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "client.schema.create_class(schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build the objects that we want to store in weaviate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unstructured_inference:Loading the Detectron2 layout model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper01.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.checkpoint.detection_checkpoint:[DetectionCheckpointer] Loading from /home/.cache/huggingface/hub/models--layoutparser--detectron2/snapshots/bdedfd979ad33a5713af334da14ec09688e7e9de/PubLayNet/faster_rcnn_R_50_FPN_3x/model_final.pth ...\n",
      "INFO:fvcore.common.checkpoint:[Checkpointer] Loading from /home/.cache/huggingface/hub/models--layoutparser--detectron2/snapshots/bdedfd979ad33a5713af334da14ec09688e7e9de/PubLayNet/faster_rcnn_R_50_FPN_3x/model_final.pth ...\n",
      "INFO:unstructured_inference:Reading PDF for file: ../data/paper01.pdf ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:root:Current section: A survey on Image Data Augmentation for Deep Learning\n",
      "INFO:root:Current section: Abstract\n",
      "INFO:root:Abstract part extracted: Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfor- tunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The applica- tion of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other character- istics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of capabilities of big data.\n",
      "INFO:root:Abstract part extracted: Data Augmentation, Big data, Image data, Deep Learning,\n",
      "INFO:root:Current section: Introduction\n",
      "INFO:unstructured_inference:Loading the Detectron2 layout model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper02.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectron2.checkpoint.detection_checkpoint:[DetectionCheckpointer] Loading from /home/.cache/huggingface/hub/models--layoutparser--detectron2/snapshots/bdedfd979ad33a5713af334da14ec09688e7e9de/PubLayNet/faster_rcnn_R_50_FPN_3x/model_final.pth ...\n",
      "INFO:fvcore.common.checkpoint:[Checkpointer] Loading from /home/.cache/huggingface/hub/models--layoutparser--detectron2/snapshots/bdedfd979ad33a5713af334da14ec09688e7e9de/PubLayNet/faster_rcnn_R_50_FPN_3x/model_final.pth ...\n",
      "INFO:unstructured_inference:Reading PDF for file: ../data/paper02.pdf ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:unstructured_inference:Detecting page elements ...\n",
      "INFO:root:Current section: A Comparison of House Price Classification with Structured and Unstructured\n",
      "INFO:root:Current section: Connor Shorten\n",
      "INFO:root:Current section: Abstract\n",
      "INFO:root:Abstract part extracted: fident and make decisions quicker, leading to a more effi- cient market. Forecasting house prices is a tool for trans- parent pricing that we explore with machine learning tech- niques.\n",
      "INFO:root:Abstract part extracted: Purchasing a home is one of the largest investments most people make. House price prediction allows indi- viduals to be informed about their asset wealth. Trans- parent pricing on homes allows for a more efficient mar- ket and economy. We report the performance of ma- chine learning models trained with structured tabular representations and unstructured text descriptions. We collected a dataset of 200 descriptions of houses which include meta-information, as well as text descriptions. We test logistic regression and multi-layer perceptron (MLP) classifiers on dividing these houses into binary buckets based on fixed price thresholds. We present an exploration into strategies to represent unstructured text descriptions of houses as inputs for machine learning models. This includes a comparison of term frequency- inverse document frequency (TF-IDF), bag-of-words (BoW), and zero-shot inference with large language models. We find the best predictive performance with TF-IDF representations of house descriptions. Readers will gain an understanding of how to use machine learn- ing models optimized with structured and unstructured text data to predict house prices.\n",
      "INFO:root:Abstract part extracted: We experiment with predicting house prices with data- driven techniques. The key to data-driven predictive analyt- ics is the feature representation of houses in the dataset. We collect a dataset of prices, meta-information about houses, and written descriptions. Meta-information includes features about houses such as the number of bedrooms, bathrooms, and square feet. Written descriptions are an emerging data source, with excitement fueled by recent advances in deep learning for natural language processing. A written house description is an open-ended report typically written by real estate brokers to describe a particular house.\n",
      "INFO:root:Abstract part extracted: Our experiments present data-driven modeling of 200 houses featurized by meta-information and written descrip- tions. We convert the written descriptions to numeric inputs through the term frequency-inverse document frequency (TF-IDF) algorithm, which is described in further detail in the Related Work section of our report. We begin by pre- senting the performance difference of a logistic regression model mapping either tabular descriptions or TF-IDF vec- tors to binary bins of house prices. The logistic regression model processing tabular data achieves 79.3% training ac- curacy and generalizes to 76.2% test accuracy. The logis- tic regression model with TF-IDF impetus achieves a 2.4% higher test accuracy at 78.6%, however, it has fit the training data very closely, achieving 100% training accuracy. This generalization gap between training and testing inspired our interest into deep learning architectures for TF-IDF repre- sentations of unstructured text data. We utilize a 3-layer non- linear MLP architecture and add dropout to control for over- fitting and limit the variance of the parametric function. We further compare TF-IDF representations of house descrip- tions to BoW representations. We additionally present the zero-shot inference of a 6-billion parameter publicly acces- sible language model to predict house prices.\n",
      "INFO:root:Current section: Introduction\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"../data\"\n",
    "\n",
    "data_objects = []\n",
    "\n",
    "for path in Path(data_folder).iterdir():\n",
    "    if path.suffix != \".pdf\":\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {path.name}...\")\n",
    "\n",
    "    elements = partition_pdf(filename=path)\n",
    "\n",
    "    abstract_extractor = AbstractExtractor()\n",
    "    abstract_extractor.consume_elements(elements)\n",
    "\n",
    "    data_object = {\"source\": path.name, \"abstract\": abstract_extractor.abstract()}\n",
    "\n",
    "    data_objects.append(data_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we upload the data objects to weaviate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with client.batch as batch:\n",
    "    for data_object in data_objects:\n",
    "        batch.add_data_object(data_object, \"Document\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'Document': [{'_additional': {'score': '0.8450042'},\n",
       "     'source': 'paper02.pdf'},\n",
       "    {'_additional': {'score': '0.26854637'}, 'source': 'paper01.pdf'}]}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query.get(\"Document\", \"source\").with_bm25(\n",
    "    query=\"some paper about housing prices\"\n",
    ").with_additional(\"score\").do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: paper02.pdf\n",
      "Summary:\n",
      "Using machine learning techniques, researchers explore predicting house prices\n",
      "with structured and unstructured data, finding that the best predictive\n",
      "performance is achieved with term frequency-inverse document frequency (TF-IDF)\n",
      "representations of house descriptions.\n",
      "\n",
      "Source: paper01.pdf\n",
      "Summary:\n",
      "Data Augmentation is a technique that enhances the size and quality of training\n",
      "datasets for Deep Learning models, particularly useful in domains with limited\n",
      "data such as medical image analysis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Please summarize the following academic abstract in a one-liner for a layperson:\n",
    "\n",
    "{abstract}\n",
    "\"\"\"\n",
    "\n",
    "results = (\n",
    "    client.query.get(\"Document\", \"source\").with_generate(single_prompt=prompt).do()\n",
    ")\n",
    "\n",
    "docs = results[\"data\"][\"Get\"][\"Document\"]\n",
    "\n",
    "for doc in docs:\n",
    "    source = doc[\"source\"]\n",
    "    abstract = doc[\"_additional\"][\"generate\"][\"singleResult\"]\n",
    "    wrapped_abstract = textwrap.fill(abstract, width=80)\n",
    "    print(f\"Source: {source}\\nSummary:\\n{wrapped_abstract}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
